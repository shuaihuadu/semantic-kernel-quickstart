
namespace KernelSyntaxExamples;

public class Example16_CustomLLM : BaseTest
{
    [Fact]
    public async Task RunAsync()
    {
        await CustomTextGenerationWithKernelFunctionAsync();
        await CustomTextGenerationAsync();
        await CustomTextGenerationStreamAsync();
    }

    private async Task CustomTextGenerationWithKernelFunctionAsync()
    {
        this.WriteLine("\n======== Custom LLM - Text Completion - KernelFunction ========");

        IKernelBuilder kernelBuilder = Kernel.CreateBuilder();

        kernelBuilder.Services.AddKeyedSingleton<ITextGenerationService>("myService1", new MyTextGenerationService());
        kernelBuilder.Services.AddKeyedSingleton<ITextGenerationService>("myService2", (_, _) => new MyTextGenerationService());

        Kernel kernel = kernelBuilder.Build();

        const string FunctionDefinition = "Write one paragraph on {{$input}}";

        KernelFunction paragraphWritingFunction = kernel.CreateFunctionFromPrompt(FunctionDefinition);

        const string Input = "Why AI is awesome?";
        this.WriteLine($"Function input: {Input}\n");

        FunctionResult result = await paragraphWritingFunction.InvokeAsync(kernel, new() { ["input"] = Input });

        this.WriteLine(result.GetValue<string>());
    }

    private async Task CustomTextGenerationAsync()
    {
        this.WriteLine("\n======== Custom LLM  - Text Completion - Raw ========");

        const string Prompt = "Write one paragraph on why AI is awesome.";

        ITextGenerationService completionService = new MyTextGenerationService();

        this.WriteLine($"Prompt: {Prompt}\n");

        TextContent result = await completionService.GetTextContentAsync(Prompt);

        this.WriteLine(result);
    }

    private async Task CustomTextGenerationStreamAsync()
    {
        this.WriteLine("\n======== Custom LLM  - Text Completion - Raw Streaming ========");

        const string Prompt = "Write one paragraph on why AI is awesome.";

        ITextGenerationService completionService = new MyTextGenerationService();

        this.WriteLine($"Prmpt: {Prompt}\n");

        IAsyncEnumerable<StreamingTextContent> result = completionService.GetStreamingTextContentsAsync(Prompt);

        await foreach (var item in result)
        {
            this.Write(item);
        }

        this.WriteLine();
    }

    private sealed class MyTextGenerationService : ITextGenerationService
    {
        private const string LLMResultText = @"The text generated by LLM. AI is awesome because it can help us solve complex problems, enhance our creativity,
and improve our lives in many ways. AI can perform tasks that are too difficult,
tedious, or dangerous for humans, such as diagnosing diseases, detecting fraud, or
exploring space. AI can also augment our abilities and inspire us to create new forms
of art, music, or literature. AI can also improve our well-being and happiness by
providing personalized recommendations, entertainment, and assistance. AI is awesome.";

        public IReadOnlyDictionary<string, object?> Attributes => throw new NotImplementedException();

        public async IAsyncEnumerable<StreamingTextContent> GetStreamingTextContentsAsync(string prompt, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, [EnumeratorCancellation] CancellationToken cancellationToken = default)
        {
            foreach (string word in LLMResultText.Split(' ', StringSplitOptions.RemoveEmptyEntries))
            {
                await Task.Delay(100, cancellationToken);

                cancellationToken.ThrowIfCancellationRequested();

                yield return new StreamingTextContent($"{word} ");
            }
        }

        public Task<IReadOnlyList<TextContent>> GetTextContentsAsync(string prompt, PromptExecutionSettings? executionSettings = null, Kernel? kernel = null, CancellationToken cancellationToken = default)
        {
            return Task.FromResult<IReadOnlyList<TextContent>>(new List<TextContent>
            {
                new(LLMResultText)
            });
        }
    }

    public Example16_CustomLLM(ITestOutputHelper output) : base(output)
    {
    }
}
